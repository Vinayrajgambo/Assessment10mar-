{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementing DL in real world applicaiton involves several key steps.\n",
    "\n",
    "Define the Problem and Data:\n",
    "Identify a specific problem you want to solve or a task to automate.\n",
    "Ensure you have a good amount of relevant data to train your deep learning model. \n",
    "This data should be well-labeled and high quality for effective learning.\n",
    "\n",
    "2. Choose the Deep Learning Model Architecture:\n",
    "Select a suitable deep learning architecture based on your problem type. \n",
    "Common choices include Convolutional Neural Networks (CNNs) for image recognition, \n",
    "Recurrent Neural Networks (RNNs) for sequence data like text, or Generative Adversarial Networks (GANs) for creating new data.\n",
    "\n",
    "3. Preprocess the Data:\n",
    "Clean and prepare your data for training. \n",
    "This might involve removing noise, handling missing values, normalization, and potentially data augmentation (creating variations) to improve model generalization.\n",
    "\n",
    "4. Train the Model:\n",
    "Split your data into training, validation, and testing sets. \n",
    "The training set trains the model, the validation set helps fine-tune hyperparameters, and the testing set evaluates the final model performance.\n",
    "Train your model by feeding the training data through the chosen architecture. \n",
    "The model learns by adjusting its internal parameters (weights and biases) to minimize the error between its predictions and the actual labels in the data.\n",
    "\n",
    "5. Evaluate and Refine:\n",
    "Evaluate the trained model's performance on the testing set using relevant metrics (accuracy, precision, recall, etc.).\n",
    "Analyze the results and identify areas for improvement. \n",
    "You might need to adjust hyperparameters, try a different model architecture, or collect more data to address shortcomings.\n",
    "\n",
    "6. Integrate and Deploy:\n",
    "Once satisfied with the model's performance, integrate it into your real-world application. \n",
    "This could involve deploying it on a server, mobile device, or embedded system for real-time predictions.\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IN ANN activation function play a crucial role in introducing non-linearity into the nwtwork.\n",
    "\n",
    "importance of activation function\n",
    "1.Non-Linearity: without activation function a ANN is simply a linear regression mode.\n",
    "                activation function introduce non-linearity, allowing the network to learn complex patterns in the data that cannot be represented by astraight line.\n",
    "\n",
    "2.Learning complex relationships: Activation functions enable the network to learn these non-linear relationships effectively. \n",
    "                                They allow neurons to \"fire\" or output a value based on the weighted sum of their inputs, creating decision boundaries beyond simple lines.\n",
    "\n",
    "                                \n",
    "3. Gradient Descent and backpropagation: These algorithms rely on calculating the error and propagating it backward through the network to adjust the weights and biases.\n",
    "\n",
    "problems without activation functions:\n",
    "\n",
    "1.Limited learning capability: ability to model complex real-world problems that often involve non-linear patterns.\n",
    "\n",
    "examples of activation functions\n",
    "1. sigmoid :0 to 1\n",
    "2. ReLU: input if positive , 0 if negative\n",
    "3. tanh: -1 to 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and prepare the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Calculate the number of parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = housing.target\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Dataset loaded and preprocessed.')\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f'Model trained. Test loss: {loss:.4f}')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
